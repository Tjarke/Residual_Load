{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize_target_var(df):\n",
    "    # fix the min and max according to phisical properties:\n",
    "    X_max = 100_000\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col] /= X_max\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(feature_matrix, target_matrix, val_days, test_days):\n",
    "    '''\n",
    "    Split a time series data set into train, validation and test set\n",
    "    INPUT:\n",
    "    - feature_matrix: dataset in numpy array form with the set of features for training\n",
    "    - target_matrix: dataset in numpy array form with the set of target variables\n",
    "    - val_days: integer representing number of days to use for the validation set\n",
    "    - test_days: integer representing number of days to use for the test set\n",
    "\n",
    "    OUTPUT:\n",
    "    - X_train: data set for training\n",
    "    - y_train: matrix with target variables for training\n",
    "    - X_val: data set for validation\n",
    "    - y_val: matrix with target variables for validation\n",
    "    - X_test: data set to test the model\n",
    "    - y_val: matrix with target variables for testing\n",
    "    '''\n",
    "\n",
    "    print('The shape of the feature data set is: {}'.format(feature_matrix.shape))\n",
    "    print('The shape of the target data set is: {}'.format(target_matrix.shape))\n",
    "\n",
    "    rows_for_test = test_days*96\n",
    "    rows_for_val = val_days*96\n",
    "\n",
    "    #target_vars_for_test = target_vars.copy()\n",
    "    #target_vars_for_test.append('Date')\n",
    "\n",
    "    #df_features = df.drop(columns=target_vars_for_test).copy()\n",
    "    #df_target = df[target_vars].copy()\n",
    "    #df_target_test = df[target_vars_for_test].copy()\n",
    "\n",
    "    X_train = feature_matrix[105_120:-(rows_for_test + rows_for_val)]\n",
    "    y_train = target_matrix[105_120:-(rows_for_test + rows_for_val)]\n",
    "    print('\\n--------------------------------------------')\n",
    "    print('The shape of the train set is: {}'.format(X_train.shape))\n",
    "    print('The shape of the target variable is: {}'.format(y_train.shape))\n",
    "    print('--------------------------------------------')\n",
    "\n",
    "    X_val = feature_matrix[X_train.shape[0]+105_120:-(rows_for_test)]\n",
    "    y_val = target_matrix[y_train.shape[0]+105_120:-(rows_for_test)]\n",
    "    print('\\n--------------------------------------------')\n",
    "    print('The shape of the validation set is: {}'.format(X_val.shape))\n",
    "    print('The shape of the target variable for the validation set is: {}'.format(y_val.shape))\n",
    "    print('--------------------------------------------')\n",
    "\n",
    "    X_test = feature_matrix[X_val.shape[0]+X_train.shape[0]+105_120:]\n",
    "    y_test = target_matrix[y_val.shape[0]+X_train.shape[0]+105_120:]\n",
    "    print('\\n--------------------------------------------')\n",
    "    print('The shape of the test set is: {}'.format(X_test.shape))\n",
    "    print('The shape of the target variable for the test set is: {}'.format(y_test.shape))\n",
    "    print('--------------------------------------------\\n')\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_metrics(y_true_with_date, y_prediction):\n",
    "\n",
    "    y_true = np.array(y_true_with_date.iloc[:,1])\n",
    "    y_pred = np.array(y_prediction)\n",
    "\n",
    "\n",
    "    # get the total error and the overall MAE\n",
    "\n",
    "    overall_mae = mean_absolute_error(y_true, y_pred)\n",
    "    absolute_error = overall_mae * len(y_true)\n",
    "\n",
    "    print('\\n----------------------------------------------')\n",
    "    print(f'The absolute error (total actual minus  forecast) in MW is: {round(absolute_error, 2)}')\n",
    "    print('----------------------------------------------\\n')\n",
    "\n",
    "    print('\\n----------------------------------------------')\n",
    "    print(f'The overall mean absolute error of the model in MW is: {overall_mae}')\n",
    "    print('----------------------------------------------\\n')\n",
    "\n",
    "    # get the overall mean absolute scaled error (MASE)\n",
    "\n",
    "    naive_forecast = y_true[1:]\n",
    "    y_true_for_mase = y_true[:-1]\n",
    "    mae_naive = mean_absolute_error(y_true_for_mase, naive_forecast)\n",
    "    overall_mae_without_first_observation = mean_absolute_error(y_true[1:], y_pred[1:])\n",
    "\n",
    "    overall_mase = overall_mae_without_first_observation/mae_naive\n",
    "\n",
    "    print('\\n----------------------------------------------')\n",
    "    print(f'The overall mean absolute scaled error of the model in MW is: {overall_mase}')\n",
    "    print('Please note: to calculate the MASE, the prediction for the first observation was omitted')\n",
    "    print('----------------------------------------------\\n')\n",
    "\n",
    "    # get the MAE for every day and return a dataframe and charts\n",
    "\n",
    "    time_stamp = np.array(\n",
    "                 pd.to_datetime(y_true_with_date.iloc[:,0], format='%Y-%m-%d %H:%M:%S').dt.date\n",
    "                 )\n",
    "\n",
    "    date_list = list()\n",
    "    y_true_list = list()\n",
    "    y_pred_list = list()\n",
    "\n",
    "    df = pd.DataFrame({'Date': time_stamp,\n",
    "                       'y_true': y_true,\n",
    "                       'y_pred': y_pred})\n",
    "\n",
    "    list_of_days = sorted(list(set(df.Date.values)))\n",
    "\n",
    "    for day in list_of_days:\n",
    "        sub_df = df.query('Date == @day')\n",
    "        date_list.append(sub_df.Date.values)\n",
    "        y_true_list.append(sub_df.y_true.values)\n",
    "        y_pred_list.append(sub_df.y_pred.values)\n",
    "\n",
    "    mae_list = list()\n",
    "    for i, j, k in zip(y_true_list, y_pred_list, date_list):\n",
    "        MAE = mean_absolute_error(i, j)\n",
    "        mae_list.append(MAE)\n",
    "\n",
    "    del df\n",
    "\n",
    "    df = pd.DataFrame({'day':list_of_days, 'MAE': mae_list},)\n",
    "\n",
    "    print('\\n----------------------------------------------')\n",
    "    print('This function also returns a dataframe with the MAE for each day')\n",
    "    print('----------------------------------------------\\n')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_hyperparameters(resolution, \n",
    "                              nan_value,\n",
    "                              window, \n",
    "                              filter_1, \n",
    "                              filter_2, \n",
    "                              optimizer, \n",
    "                              epochs):\n",
    "    \n",
    "    if resolution == '16x10':\n",
    "        path = '/Users/juangarcia/Documents/Data_Science/03_DSR/Final_Project/erste_repo/Residual_Load/'\n",
    "        file = f'Data_collection_weather/feature_channel_{resolution}.npy'\n",
    "        feature_channel = np.load(path+file, allow_pickle=False)\n",
    "    else:\n",
    "        path = '/Users/juangarcia/Documents/Data_Science/03_DSR/Final_Project/erste_repo/Residual_Load/'\n",
    "        weather_file = f'Data_collection_weather/feature_channel_{resolution}.npy'\n",
    "        feature_channel = np.load(path+weather_file, allow_pickle=False)\n",
    "        path = '/Users/juangarcia/Documents/Data_Science/03_DSR/Final_Project/erste_repo/Residual_Load/'\n",
    "        ic_file = f'Feature_engineering/installed_capacities_{resolution}.npy'\n",
    "        ic_channel = np.load(path+ic_file, allow_pickle=False)\n",
    "        feature_channel = np.dstack((feature_channel, ic_channel))\n",
    "\n",
    "    # rearange the axis to get the examples as the first dimension for the use in tensorflow\n",
    "    feature_channel = np.moveaxis(feature_channel, -1, 0)\n",
    "    \n",
    "    # get rid of all nans - replace them with -1\n",
    "    feature_channel = np.nan_to_num(feature_channel, nan=nan_value)\n",
    "    \n",
    "    # load the target values\n",
    "    path = '/Users/juangarcia/Documents/Data_Science/03_DSR/Final_Project/erste_repo/Residual_Load/'\n",
    "    file_load = 'Data_collection_entsoe/Day_ahead_dataset.csv'\n",
    "    df_load = pd.read_csv(path+file_load)\n",
    "\n",
    "    # keep only the target values and get rid of nans\n",
    "    df_load.drop(columns=['index', 'Day ahead/System total load in MAW',\n",
    "           'Day ahead/Solar in MAW',\n",
    "           'Day ahead/Wind Onshore in MAW', 'Day ahead/Wind Offshore in MAW'], inplace=True)\n",
    "\n",
    "    df_load = df_load.interpolate(method='linear')\n",
    "    \n",
    "    # normalize the target variables\n",
    "    df_load_norm = min_max_normalize_target_var(df_load.iloc[:,1:]) # avoid Date\n",
    "    \n",
    "    # create numpy array\n",
    "    np_load = df_load_norm.to_numpy(copy=True)\n",
    "    \n",
    "    # create the training, validation and test sets\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(feature_channel, \n",
    "                                                                          np_load, 90, 90)\n",
    "    \n",
    "    # get the model running\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(filter_1, window,\n",
    "              activation='relu',\n",
    "              input_shape=(16, 10, 9))\n",
    "             )\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(filter_2, window,\n",
    "              activation='relu')\n",
    "             )\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_error'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=128,\n",
    "                        epochs = epochs,\n",
    "                        validation_data=(X_val,y_val),\n",
    "                        shuffle=False)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_true = (y_test*100_000).copy()\n",
    "    y_prediction = (y_pred*100_000).copy()\n",
    "    \n",
    "    y_true_with_date = pd.DataFrame({'Date':df_load.iloc[-y_test.shape[0]:,0],\n",
    "                                 'solar':y_true[:,0], \n",
    "                                 'wind_onshore':y_true[:,1], \n",
    "                                 'load':y_true[:,2], \n",
    "                                 'wind_offshore':y_true[:,3]})\n",
    "\n",
    "\n",
    "    list_names = [\"solar\",\"wind_onshore\", \"load\", \"wind_offshore\"]\n",
    "\n",
    "    metrics_dict = dict()\n",
    "    for i in range(len(y_pred[0])):\n",
    "        print(\"\\n=================================\")\n",
    "        print(f\"{list_names[i]}\")\n",
    "        metrics_dict[list_names[i]] = get_model_metrics(y_true_with_date.iloc[:,[0,i+1]],y_prediction[:,i])\n",
    "        print(\"=================================\\n\")\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------\n",
      "training model 1...\n",
      "The shape of the feature data set is: (204096, 16, 10, 9)\n",
      "The shape of the target data set is: (204096, 4)\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the train set is: (81696, 16, 10, 9)\n",
      "The shape of the target variable is: (81696, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the validation set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the validation set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the test set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the test set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "Epoch 1/30\n",
      "639/639 [==============================] - 6s 10ms/step - loss: 0.0042 - mean_absolute_error: 0.0437 - val_loss: 0.0033 - val_mean_absolute_error: 0.0414\n",
      "Epoch 2/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0359 - val_loss: 0.0033 - val_mean_absolute_error: 0.0398\n",
      "Epoch 3/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0025 - mean_absolute_error: 0.0333 - val_loss: 0.0031 - val_mean_absolute_error: 0.0394\n",
      "Epoch 4/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0024 - mean_absolute_error: 0.0320 - val_loss: 0.0030 - val_mean_absolute_error: 0.0387\n",
      "Epoch 5/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0310 - val_loss: 0.0031 - val_mean_absolute_error: 0.0401\n",
      "Epoch 6/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0303 - val_loss: 0.0030 - val_mean_absolute_error: 0.0387\n",
      "Epoch 7/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0300 - val_loss: 0.0033 - val_mean_absolute_error: 0.0416\n",
      "Epoch 8/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0296 - val_loss: 0.0029 - val_mean_absolute_error: 0.0381\n",
      "Epoch 9/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0293 - val_loss: 0.0030 - val_mean_absolute_error: 0.0390\n",
      "Epoch 10/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0289 - val_loss: 0.0027 - val_mean_absolute_error: 0.0362\n",
      "Epoch 11/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0286 - val_loss: 0.0028 - val_mean_absolute_error: 0.0365\n",
      "Epoch 12/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0285 - val_loss: 0.0029 - val_mean_absolute_error: 0.0369\n",
      "Epoch 13/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0282 - val_loss: 0.0026 - val_mean_absolute_error: 0.0342\n",
      "Epoch 14/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0280 - val_loss: 0.0025 - val_mean_absolute_error: 0.0329\n",
      "Epoch 15/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0278 - val_loss: 0.0026 - val_mean_absolute_error: 0.0336\n",
      "Epoch 16/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0274 - val_loss: 0.0025 - val_mean_absolute_error: 0.0328\n",
      "Epoch 17/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0273 - val_loss: 0.0025 - val_mean_absolute_error: 0.0324\n",
      "Epoch 18/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0270 - val_loss: 0.0026 - val_mean_absolute_error: 0.0330\n",
      "Epoch 19/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0268 - val_loss: 0.0026 - val_mean_absolute_error: 0.0342\n",
      "Epoch 20/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0267 - val_loss: 0.0026 - val_mean_absolute_error: 0.0346\n",
      "Epoch 21/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0266 - val_loss: 0.0026 - val_mean_absolute_error: 0.0338\n",
      "Epoch 22/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0265 - val_loss: 0.0025 - val_mean_absolute_error: 0.0333\n",
      "Epoch 23/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0263 - val_loss: 0.0028 - val_mean_absolute_error: 0.0344\n",
      "Epoch 24/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0263 - val_loss: 0.0028 - val_mean_absolute_error: 0.0347\n",
      "Epoch 25/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0260 - val_loss: 0.0027 - val_mean_absolute_error: 0.0333\n",
      "Epoch 26/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0259 - val_loss: 0.0026 - val_mean_absolute_error: 0.0331\n",
      "Epoch 27/30\n",
      "639/639 [==============================] - 6s 10ms/step - loss: 0.0017 - mean_absolute_error: 0.0257 - val_loss: 0.0025 - val_mean_absolute_error: 0.0330\n",
      "Epoch 28/30\n",
      "639/639 [==============================] - 6s 10ms/step - loss: 0.0017 - mean_absolute_error: 0.0259 - val_loss: 0.0026 - val_mean_absolute_error: 0.0331\n",
      "Epoch 29/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0256 - val_loss: 0.0023 - val_mean_absolute_error: 0.0314\n",
      "Epoch 30/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0016 - mean_absolute_error: 0.0254 - val_loss: 0.0024 - val_mean_absolute_error: 0.0313\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 25488283.58\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2950.032821197587\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 7.327980412175957\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 18657361.29\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2159.416815736807\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 10.91992240158319\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 59000806.85\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 6828.797089111695\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 13.070052426878123\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 8028121.5\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 929.1807288001464\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 10.847455141993212\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "training model 2...\n",
      "The shape of the feature data set is: (204096, 16, 10, 9)\n",
      "The shape of the target data set is: (204096, 4)\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the train set is: (81696, 16, 10, 9)\n",
      "The shape of the target variable is: (81696, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the validation set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the validation set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the test set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the test set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "Epoch 1/30\n",
      "639/639 [==============================] - 7s 10ms/step - loss: 0.0044 - mean_absolute_error: 0.0452 - val_loss: 0.0041 - val_mean_absolute_error: 0.0472\n",
      "Epoch 2/30\n",
      "639/639 [==============================] - 6s 10ms/step - loss: 0.0030 - mean_absolute_error: 0.0380 - val_loss: 0.0033 - val_mean_absolute_error: 0.0398\n",
      "Epoch 3/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0026 - mean_absolute_error: 0.0347 - val_loss: 0.0030 - val_mean_absolute_error: 0.0359\n",
      "Epoch 4/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0025 - mean_absolute_error: 0.0330 - val_loss: 0.0028 - val_mean_absolute_error: 0.0347\n",
      "Epoch 5/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0319 - val_loss: 0.0026 - val_mean_absolute_error: 0.0339\n",
      "Epoch 6/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0313 - val_loss: 0.0026 - val_mean_absolute_error: 0.0331\n",
      "Epoch 7/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0308 - val_loss: 0.0025 - val_mean_absolute_error: 0.0329\n",
      "Epoch 8/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0304 - val_loss: 0.0024 - val_mean_absolute_error: 0.0324\n",
      "Epoch 9/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0299 - val_loss: 0.0024 - val_mean_absolute_error: 0.0319\n",
      "Epoch 10/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0296 - val_loss: 0.0023 - val_mean_absolute_error: 0.0313\n",
      "Epoch 11/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0291 - val_loss: 0.0024 - val_mean_absolute_error: 0.0321\n",
      "Epoch 12/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0289 - val_loss: 0.0022 - val_mean_absolute_error: 0.0309\n",
      "Epoch 13/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0287 - val_loss: 0.0023 - val_mean_absolute_error: 0.0314\n",
      "Epoch 14/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0285 - val_loss: 0.0022 - val_mean_absolute_error: 0.0311\n",
      "Epoch 15/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0282 - val_loss: 0.0022 - val_mean_absolute_error: 0.0304\n",
      "Epoch 16/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0279 - val_loss: 0.0023 - val_mean_absolute_error: 0.0317\n",
      "Epoch 17/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0279 - val_loss: 0.0022 - val_mean_absolute_error: 0.0311\n",
      "Epoch 18/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0276 - val_loss: 0.0023 - val_mean_absolute_error: 0.0332\n",
      "Epoch 19/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0273 - val_loss: 0.0024 - val_mean_absolute_error: 0.0335\n",
      "Epoch 20/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0272 - val_loss: 0.0023 - val_mean_absolute_error: 0.0330\n",
      "Epoch 21/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0269 - val_loss: 0.0025 - val_mean_absolute_error: 0.0345\n",
      "Epoch 22/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0268 - val_loss: 0.0024 - val_mean_absolute_error: 0.0339\n",
      "Epoch 23/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0266 - val_loss: 0.0023 - val_mean_absolute_error: 0.0316\n",
      "Epoch 24/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0266 - val_loss: 0.0023 - val_mean_absolute_error: 0.0323\n",
      "Epoch 25/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0263 - val_loss: 0.0026 - val_mean_absolute_error: 0.0343\n",
      "Epoch 26/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0262 - val_loss: 0.0023 - val_mean_absolute_error: 0.0323\n",
      "Epoch 27/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0260 - val_loss: 0.0025 - val_mean_absolute_error: 0.0335\n",
      "Epoch 28/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0257 - val_loss: 0.0025 - val_mean_absolute_error: 0.0342\n",
      "Epoch 29/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0016 - mean_absolute_error: 0.0255 - val_loss: 0.0025 - val_mean_absolute_error: 0.0332\n",
      "Epoch 30/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0016 - mean_absolute_error: 0.0253 - val_loss: 0.0024 - val_mean_absolute_error: 0.0333\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 22441861.79\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2597.4377066914167\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 6.45197677282598\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 24550790.3\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2841.5266548336244\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 14.36718446225333\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 60170378.8\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 6964.1642128600015\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 13.330494246306138\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 7541277.76\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 872.8330743323115\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 10.190136325717269\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "training model 3...\n",
      "The shape of the feature data set is: (204096, 16, 10, 9)\n",
      "The shape of the target data set is: (204096, 4)\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the train set is: (81696, 16, 10, 9)\n",
      "The shape of the target variable is: (81696, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the validation set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the validation set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the test set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the test set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "Epoch 1/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0043 - mean_absolute_error: 0.0444 - val_loss: 0.0037 - val_mean_absolute_error: 0.0446\n",
      "Epoch 2/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0355 - val_loss: 0.0029 - val_mean_absolute_error: 0.0371\n",
      "Epoch 3/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0025 - mean_absolute_error: 0.0330 - val_loss: 0.0026 - val_mean_absolute_error: 0.0340\n",
      "Epoch 4/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0024 - mean_absolute_error: 0.0318 - val_loss: 0.0026 - val_mean_absolute_error: 0.0341\n",
      "Epoch 5/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0310 - val_loss: 0.0024 - val_mean_absolute_error: 0.0328\n",
      "Epoch 6/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0303 - val_loss: 0.0024 - val_mean_absolute_error: 0.0335\n",
      "Epoch 7/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0299 - val_loss: 0.0024 - val_mean_absolute_error: 0.0329\n",
      "Epoch 8/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0295 - val_loss: 0.0025 - val_mean_absolute_error: 0.0330\n",
      "Epoch 9/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0293 - val_loss: 0.0025 - val_mean_absolute_error: 0.0330\n",
      "Epoch 10/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0290 - val_loss: 0.0024 - val_mean_absolute_error: 0.0315\n",
      "Epoch 11/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0289 - val_loss: 0.0023 - val_mean_absolute_error: 0.0313\n",
      "Epoch 12/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0286 - val_loss: 0.0024 - val_mean_absolute_error: 0.0317\n",
      "Epoch 13/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0283 - val_loss: 0.0024 - val_mean_absolute_error: 0.0317\n",
      "Epoch 14/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0280 - val_loss: 0.0024 - val_mean_absolute_error: 0.0317\n",
      "Epoch 15/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0277 - val_loss: 0.0025 - val_mean_absolute_error: 0.0327\n",
      "Epoch 16/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0275 - val_loss: 0.0025 - val_mean_absolute_error: 0.0322\n",
      "Epoch 17/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0271 - val_loss: 0.0024 - val_mean_absolute_error: 0.0316\n",
      "Epoch 18/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0268 - val_loss: 0.0025 - val_mean_absolute_error: 0.0326\n",
      "Epoch 19/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0266 - val_loss: 0.0024 - val_mean_absolute_error: 0.0321\n",
      "Epoch 20/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0263 - val_loss: 0.0025 - val_mean_absolute_error: 0.0323\n",
      "Epoch 21/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0018 - mean_absolute_error: 0.0263 - val_loss: 0.0025 - val_mean_absolute_error: 0.0323\n",
      "Epoch 22/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0261 - val_loss: 0.0025 - val_mean_absolute_error: 0.0320\n",
      "Epoch 23/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0260 - val_loss: 0.0024 - val_mean_absolute_error: 0.0315\n",
      "Epoch 24/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0259 - val_loss: 0.0024 - val_mean_absolute_error: 0.0315\n",
      "Epoch 25/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0257 - val_loss: 0.0024 - val_mean_absolute_error: 0.0311\n",
      "Epoch 26/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0017 - mean_absolute_error: 0.0256 - val_loss: 0.0024 - val_mean_absolute_error: 0.0313\n",
      "Epoch 27/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0016 - mean_absolute_error: 0.0254 - val_loss: 0.0027 - val_mean_absolute_error: 0.0326\n",
      "Epoch 28/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0016 - mean_absolute_error: 0.0253 - val_loss: 0.0027 - val_mean_absolute_error: 0.0324\n",
      "Epoch 29/30\n",
      "639/639 [==============================] - 7s 10ms/step - loss: 0.0016 - mean_absolute_error: 0.0253 - val_loss: 0.0029 - val_mean_absolute_error: 0.0340\n",
      "Epoch 30/30\n",
      "639/639 [==============================] - 7s 10ms/step - loss: 0.0016 - mean_absolute_error: 0.0251 - val_loss: 0.0026 - val_mean_absolute_error: 0.0326\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 22869782.13\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2646.9655244587334\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 6.57515571647891\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 17623678.31\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2039.7775825111955\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 10.31517375170151\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 64149432.48\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 7424.702833150272\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 14.210631347962982\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 7304481.99\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 845.4261567480207\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 9.869210645290284\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "training model 4...\n",
      "The shape of the feature data set is: (204096, 16, 10, 9)\n",
      "The shape of the target data set is: (204096, 4)\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the train set is: (81696, 16, 10, 9)\n",
      "The shape of the target variable is: (81696, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the validation set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the validation set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the test set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the test set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "Epoch 1/30\n",
      "639/639 [==============================] - 7s 10ms/step - loss: 0.0059 - mean_absolute_error: 0.0502 - val_loss: 0.0034 - val_mean_absolute_error: 0.0424\n",
      "Epoch 2/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0032 - mean_absolute_error: 0.0380 - val_loss: 0.0030 - val_mean_absolute_error: 0.0392\n",
      "Epoch 3/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0027 - mean_absolute_error: 0.0346 - val_loss: 0.0028 - val_mean_absolute_error: 0.0364\n",
      "Epoch 4/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0025 - mean_absolute_error: 0.0331 - val_loss: 0.0028 - val_mean_absolute_error: 0.0357\n",
      "Epoch 5/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0024 - mean_absolute_error: 0.0319 - val_loss: 0.0028 - val_mean_absolute_error: 0.0352\n",
      "Epoch 6/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0314 - val_loss: 0.0026 - val_mean_absolute_error: 0.0337\n",
      "Epoch 7/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0310 - val_loss: 0.0025 - val_mean_absolute_error: 0.0331\n",
      "Epoch 8/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0306 - val_loss: 0.0025 - val_mean_absolute_error: 0.0333\n",
      "Epoch 9/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0302 - val_loss: 0.0025 - val_mean_absolute_error: 0.0329\n",
      "Epoch 10/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0301 - val_loss: 0.0025 - val_mean_absolute_error: 0.0323\n",
      "Epoch 11/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0298 - val_loss: 0.0024 - val_mean_absolute_error: 0.0319\n",
      "Epoch 12/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0295 - val_loss: 0.0025 - val_mean_absolute_error: 0.0331\n",
      "Epoch 13/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0293 - val_loss: 0.0025 - val_mean_absolute_error: 0.0334\n",
      "Epoch 14/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0292 - val_loss: 0.0025 - val_mean_absolute_error: 0.0328\n",
      "Epoch 15/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0021 - mean_absolute_error: 0.0290 - val_loss: 0.0024 - val_mean_absolute_error: 0.0319\n",
      "Epoch 16/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0288 - val_loss: 0.0023 - val_mean_absolute_error: 0.0322\n",
      "Epoch 17/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0289 - val_loss: 0.0022 - val_mean_absolute_error: 0.0308\n",
      "Epoch 18/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0286 - val_loss: 0.0023 - val_mean_absolute_error: 0.0322\n",
      "Epoch 19/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0286 - val_loss: 0.0026 - val_mean_absolute_error: 0.0343\n",
      "Epoch 20/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0285 - val_loss: 0.0024 - val_mean_absolute_error: 0.0328\n",
      "Epoch 21/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0283 - val_loss: 0.0024 - val_mean_absolute_error: 0.0324\n",
      "Epoch 22/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0282 - val_loss: 0.0025 - val_mean_absolute_error: 0.0329\n",
      "Epoch 23/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0280 - val_loss: 0.0026 - val_mean_absolute_error: 0.0336\n",
      "Epoch 24/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0279 - val_loss: 0.0025 - val_mean_absolute_error: 0.0335\n",
      "Epoch 25/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0278 - val_loss: 0.0025 - val_mean_absolute_error: 0.0336\n",
      "Epoch 26/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0278 - val_loss: 0.0024 - val_mean_absolute_error: 0.0323\n",
      "Epoch 27/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0275 - val_loss: 0.0022 - val_mean_absolute_error: 0.0309\n",
      "Epoch 28/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0275 - val_loss: 0.0023 - val_mean_absolute_error: 0.0317\n",
      "Epoch 29/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0274 - val_loss: 0.0025 - val_mean_absolute_error: 0.0328\n",
      "Epoch 30/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0274 - val_loss: 0.0023 - val_mean_absolute_error: 0.0310\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 23537240.43\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2724.2176419724055\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 6.7668171468752165\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 17787613.09\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2058.751514961874\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 10.410072028243688\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 55932980.57\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 6473.724602481612\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 12.390147981274866\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 9134858.03\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 1057.2752346308039\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 12.341494277421324\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "training model 5...\n",
      "The shape of the feature data set is: (204096, 16, 10, 9)\n",
      "The shape of the target data set is: (204096, 4)\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the train set is: (81696, 16, 10, 9)\n",
      "The shape of the target variable is: (81696, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the validation set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the validation set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the test set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the test set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "Epoch 1/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.1588 - mean_absolute_error: 0.1840 - val_loss: 0.0037 - val_mean_absolute_error: 0.0464\n",
      "Epoch 2/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0044 - mean_absolute_error: 0.0471 - val_loss: 0.0056 - val_mean_absolute_error: 0.0591\n",
      "Epoch 3/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0035 - mean_absolute_error: 0.0411 - val_loss: 0.0032 - val_mean_absolute_error: 0.0403\n",
      "Epoch 4/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0375 - val_loss: 0.0029 - val_mean_absolute_error: 0.0383\n",
      "Epoch 5/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0359 - val_loss: 0.0027 - val_mean_absolute_error: 0.0366\n",
      "Epoch 6/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0027 - mean_absolute_error: 0.0349 - val_loss: 0.0026 - val_mean_absolute_error: 0.0370\n",
      "Epoch 7/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0026 - mean_absolute_error: 0.0340 - val_loss: 0.0024 - val_mean_absolute_error: 0.0332\n",
      "Epoch 8/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0025 - mean_absolute_error: 0.0333 - val_loss: 0.0024 - val_mean_absolute_error: 0.0342\n",
      "Epoch 9/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0025 - mean_absolute_error: 0.0329 - val_loss: 0.0024 - val_mean_absolute_error: 0.0332\n",
      "Epoch 10/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0024 - mean_absolute_error: 0.0323 - val_loss: 0.0024 - val_mean_absolute_error: 0.0332\n",
      "Epoch 11/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0024 - mean_absolute_error: 0.0322 - val_loss: 0.0022 - val_mean_absolute_error: 0.0320\n",
      "Epoch 12/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0024 - mean_absolute_error: 0.0319 - val_loss: 0.0023 - val_mean_absolute_error: 0.0322\n",
      "Epoch 13/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0024 - mean_absolute_error: 0.0317 - val_loss: 0.0023 - val_mean_absolute_error: 0.0330\n",
      "Epoch 14/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0314 - val_loss: 0.0023 - val_mean_absolute_error: 0.0330\n",
      "Epoch 15/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0314 - val_loss: 0.0023 - val_mean_absolute_error: 0.0326\n",
      "Epoch 16/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0024 - mean_absolute_error: 0.0316 - val_loss: 0.0024 - val_mean_absolute_error: 0.0337\n",
      "Epoch 17/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0312 - val_loss: 0.0027 - val_mean_absolute_error: 0.0351\n",
      "Epoch 18/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0311 - val_loss: 0.0023 - val_mean_absolute_error: 0.0329\n",
      "Epoch 19/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0310 - val_loss: 0.0026 - val_mean_absolute_error: 0.0344\n",
      "Epoch 20/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0308 - val_loss: 0.0024 - val_mean_absolute_error: 0.0332\n",
      "Epoch 21/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0307 - val_loss: 0.0022 - val_mean_absolute_error: 0.0326\n",
      "Epoch 22/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0307 - val_loss: 0.0024 - val_mean_absolute_error: 0.0329\n",
      "Epoch 23/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0023 - mean_absolute_error: 0.0306 - val_loss: 0.0024 - val_mean_absolute_error: 0.0328\n",
      "Epoch 24/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0304 - val_loss: 0.0024 - val_mean_absolute_error: 0.0328\n",
      "Epoch 25/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0305 - val_loss: 0.0025 - val_mean_absolute_error: 0.0333\n",
      "Epoch 26/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0303 - val_loss: 0.0024 - val_mean_absolute_error: 0.0326\n",
      "Epoch 27/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0302 - val_loss: 0.0024 - val_mean_absolute_error: 0.0327\n",
      "Epoch 28/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0301 - val_loss: 0.0024 - val_mean_absolute_error: 0.0329\n",
      "Epoch 29/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0303 - val_loss: 0.0024 - val_mean_absolute_error: 0.0328\n",
      "Epoch 30/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0022 - mean_absolute_error: 0.0303 - val_loss: 0.0024 - val_mean_absolute_error: 0.0328\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 26640907.73\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 3083.4383944255474\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 7.659206670076791\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 16447256.33\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 1903.6176312253983\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 9.62602844759321\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 63037134.85\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 7295.964682181014\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 13.964270084572345\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 11876008.46\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 1374.5380158029927\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 16.0433222010049\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "training model 6...\n",
      "The shape of the feature data set is: (204096, 16, 10, 9)\n",
      "The shape of the target data set is: (204096, 4)\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the train set is: (81696, 16, 10, 9)\n",
      "The shape of the target variable is: (81696, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the validation set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the validation set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the test set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the test set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "Epoch 1/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 15.1258 - mean_absolute_error: 1.7668 - val_loss: 0.0150 - val_mean_absolute_error: 0.0980\n",
      "Epoch 2/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0178 - mean_absolute_error: 0.0776 - val_loss: 0.0038 - val_mean_absolute_error: 0.0464\n",
      "Epoch 3/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0086 - mean_absolute_error: 0.0540 - val_loss: 0.0033 - val_mean_absolute_error: 0.0403\n",
      "Epoch 4/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0085 - mean_absolute_error: 0.0557 - val_loss: 0.0030 - val_mean_absolute_error: 0.0387\n",
      "Epoch 5/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0053 - mean_absolute_error: 0.0463 - val_loss: 0.0044 - val_mean_absolute_error: 0.0495\n",
      "Epoch 6/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0039 - mean_absolute_error: 0.0419 - val_loss: 0.0031 - val_mean_absolute_error: 0.0383\n",
      "Epoch 7/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0037 - mean_absolute_error: 0.0398 - val_loss: 0.0029 - val_mean_absolute_error: 0.0380\n",
      "Epoch 8/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0044 - mean_absolute_error: 0.0389 - val_loss: 0.0030 - val_mean_absolute_error: 0.0378\n",
      "Epoch 9/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0034 - mean_absolute_error: 0.0378 - val_loss: 0.0029 - val_mean_absolute_error: 0.0367\n",
      "Epoch 10/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0039 - mean_absolute_error: 0.0383 - val_loss: 0.0030 - val_mean_absolute_error: 0.0383\n",
      "Epoch 11/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0363 - val_loss: 0.0027 - val_mean_absolute_error: 0.0365\n",
      "Epoch 12/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0033 - mean_absolute_error: 0.0370 - val_loss: 0.0027 - val_mean_absolute_error: 0.0364\n",
      "Epoch 13/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0363 - val_loss: 0.0028 - val_mean_absolute_error: 0.0367\n",
      "Epoch 14/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0029 - mean_absolute_error: 0.0359 - val_loss: 0.0028 - val_mean_absolute_error: 0.0367\n",
      "Epoch 15/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0038 - mean_absolute_error: 0.0366 - val_loss: 0.0029 - val_mean_absolute_error: 0.0375\n",
      "Epoch 16/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0354 - val_loss: 0.0029 - val_mean_absolute_error: 0.0373\n",
      "Epoch 17/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0357 - val_loss: 0.0028 - val_mean_absolute_error: 0.0371\n",
      "Epoch 18/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0352 - val_loss: 0.0027 - val_mean_absolute_error: 0.0365\n",
      "Epoch 19/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0352 - val_loss: 0.0028 - val_mean_absolute_error: 0.0374\n",
      "Epoch 20/30\n",
      "639/639 [==============================] - 7s 10ms/step - loss: 0.0028 - mean_absolute_error: 0.0351 - val_loss: 0.0028 - val_mean_absolute_error: 0.0369\n",
      "Epoch 21/30\n",
      "639/639 [==============================] - 7s 10ms/step - loss: 0.0027 - mean_absolute_error: 0.0351 - val_loss: 0.0028 - val_mean_absolute_error: 0.0367\n",
      "Epoch 22/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0353 - val_loss: 0.0026 - val_mean_absolute_error: 0.0357\n",
      "Epoch 23/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0350 - val_loss: 0.0027 - val_mean_absolute_error: 0.0372\n",
      "Epoch 24/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0027 - mean_absolute_error: 0.0349 - val_loss: 0.0028 - val_mean_absolute_error: 0.0377\n",
      "Epoch 25/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0027 - mean_absolute_error: 0.0347 - val_loss: 0.0029 - val_mean_absolute_error: 0.0384\n",
      "Epoch 26/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0026 - mean_absolute_error: 0.0343 - val_loss: 0.0029 - val_mean_absolute_error: 0.0383\n",
      "Epoch 27/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0026 - mean_absolute_error: 0.0342 - val_loss: 0.0028 - val_mean_absolute_error: 0.0381\n",
      "Epoch 28/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0026 - mean_absolute_error: 0.0343 - val_loss: 0.0029 - val_mean_absolute_error: 0.0384\n",
      "Epoch 29/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0027 - mean_absolute_error: 0.0344 - val_loss: 0.0028 - val_mean_absolute_error: 0.0382\n",
      "Epoch 30/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0026 - mean_absolute_error: 0.0343 - val_loss: 0.0029 - val_mean_absolute_error: 0.0386\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 26023109.51\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 3011.9339706365745\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 7.481624933282142\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 33212306.64\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 3844.016971902439\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 19.436261990227834\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 60706216.64\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 7026.18248205185\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 13.447589260505888\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 14908048.21\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 1725.4685433685572\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 20.13963381020743\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "training model 7...\n",
      "The shape of the feature data set is: (204096, 16, 10, 9)\n",
      "The shape of the target data set is: (204096, 4)\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the train set is: (81696, 16, 10, 9)\n",
      "The shape of the target variable is: (81696, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the validation set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the validation set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the test set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the test set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "Epoch 1/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 1383.9810 - mean_absolute_error: 17.2064 - val_loss: 15.3029 - val_mean_absolute_error: 3.1895\n",
      "Epoch 2/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 7.8943 - mean_absolute_error: 1.1611 - val_loss: 0.0158 - val_mean_absolute_error: 0.0970\n",
      "Epoch 3/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.3673 - mean_absolute_error: 0.1796 - val_loss: 0.0044 - val_mean_absolute_error: 0.0505\n",
      "Epoch 4/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0817 - mean_absolute_error: 0.0852 - val_loss: 0.0058 - val_mean_absolute_error: 0.0583\n",
      "Epoch 5/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0143 - mean_absolute_error: 0.0610 - val_loss: 0.0038 - val_mean_absolute_error: 0.0456\n",
      "Epoch 6/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0251 - mean_absolute_error: 0.0625 - val_loss: 0.0036 - val_mean_absolute_error: 0.0473\n",
      "Epoch 7/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0056 - mean_absolute_error: 0.0507 - val_loss: 0.0034 - val_mean_absolute_error: 0.0432\n",
      "Epoch 8/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0179 - mean_absolute_error: 0.0611 - val_loss: 0.0039 - val_mean_absolute_error: 0.0457\n",
      "Epoch 9/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0045 - mean_absolute_error: 0.0471 - val_loss: 0.0039 - val_mean_absolute_error: 0.0467\n",
      "Epoch 10/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0046 - mean_absolute_error: 0.0466 - val_loss: 0.0047 - val_mean_absolute_error: 0.0494\n",
      "Epoch 11/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0101 - mean_absolute_error: 0.0495 - val_loss: 0.0049 - val_mean_absolute_error: 0.0500\n",
      "Epoch 12/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0069 - mean_absolute_error: 0.0561 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 13/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0554 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 14/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0056 - mean_absolute_error: 0.0553 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 15/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0553 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 16/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 17/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 18/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 19/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 20/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 21/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 22/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 23/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 24/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 25/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 26/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 27/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 28/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 29/30\n",
      "639/639 [==============================] - 6s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "Epoch 30/30\n",
      "639/639 [==============================] - 7s 10ms/step - loss: 0.0057 - mean_absolute_error: 0.0552 - val_loss: 0.0065 - val_mean_absolute_error: 0.0628\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 58778982.72\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 6803.12300016066\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 16.89759620056651\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 62096297.96\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 7187.071523384474\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 36.34354700383662\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 72219263.53\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 8358.711056583457\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 15.997409927774124\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 14811170.85\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 1714.2558853332644\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 20.00995929189868\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nan_values = [-0.0001, -0.01, -0.1, -1, -10, -100, -1000]\n",
    "#first_filters = [256, 128, 64, 64, 128, 256]\n",
    "#second_filters = [64, 64, 128, 256, 256, 128]\n",
    "#optimizer = ['rmsprop', 'adam', 'rmsprop', 'adam', 'rmsprop', 'adam']\n",
    "#sliding_window = [(3,3), (2,2), (3,3), (2,2), (3,3), (2,2)]\n",
    "model_number = range(1,8)\n",
    "\n",
    "model_dict = dict()\n",
    "for num,nan in zip(model_number, nan_values):\n",
    "    print('\\n-----------------------------------------------------------')\n",
    "    print(f'training model {num}...')\n",
    "    model_dict[f'model_{num}'] = train_model_hyperparameters('16x10', \n",
    "                                                              nan,\n",
    "                                                              (3,3), \n",
    "                                                              64, \n",
    "                                                              64, \n",
    "                                                              'rmsprop', \n",
    "                                                              30)\n",
    "    print('-----------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10, 9, 204096)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all feature_channels\n",
    "\n",
    "path = '/Users/juangarcia/Documents/Data_Science/03_DSR/Final_Project/erste_repo/Residual_Load/'\n",
    "file = 'Data_collection_weather/feature_channel_16x10.npy'\n",
    "\n",
    "feature_channel = np.load(path+file, allow_pickle=False)\n",
    "feature_channel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204096, 16, 10, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rearange the axis to get the examples as the first dimension for the use in tensorflow\n",
    "feature_channel = np.moveaxis(feature_channel, -1, 0)\n",
    "feature_channel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of all nans - replace them with -1\n",
    "feature_channel = np.nan_to_num(feature_channel, nan=-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure the change did work:\n",
    "plt.figure(figsize = (6,8))\n",
    "sns.heatmap(feature_channel[80_045,::-1,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204096, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the target values\n",
    "path = '/Users/juangarcia/Documents/Data_Science/03_DSR/Final_Project/erste_repo/Residual_Load/'\n",
    "file_load = 'Data_collection_entsoe/Day_ahead_dataset.csv'\n",
    "df_load = pd.read_csv(path+file_load)\n",
    "\n",
    "df_load.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204096, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Realised/Solar in MAW</th>\n",
       "      <th>Realised/Wind Onshore in MAW</th>\n",
       "      <th>Realised/System total load in MAW</th>\n",
       "      <th>Realised/Wind Offshore in MAW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8113.0</td>\n",
       "      <td>42976.0</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-31 23:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8092.0</td>\n",
       "      <td>42540.0</td>\n",
       "      <td>517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-31 23:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8161.0</td>\n",
       "      <td>42638.0</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-31 23:45:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8146.0</td>\n",
       "      <td>42483.0</td>\n",
       "      <td>515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8183.0</td>\n",
       "      <td>41917.0</td>\n",
       "      <td>515.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  Realised/Solar in MAW  Realised/Wind Onshore in MAW  \\\n",
       "0  2014-12-31 23:00:00                    0.0                        8113.0   \n",
       "1  2014-12-31 23:15:00                    0.0                        8092.0   \n",
       "2  2014-12-31 23:30:00                    0.0                        8161.0   \n",
       "3  2014-12-31 23:45:00                    0.0                        8146.0   \n",
       "4  2015-01-01 00:00:00                    0.0                        8183.0   \n",
       "\n",
       "   Realised/System total load in MAW  Realised/Wind Offshore in MAW  \n",
       "0                            42976.0                          520.0  \n",
       "1                            42540.0                          517.0  \n",
       "2                            42638.0                          514.0  \n",
       "3                            42483.0                          515.0  \n",
       "4                            41917.0                          515.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the target values\n",
    "df_load.drop(columns=['index', 'Day ahead/System total load in MAW',\n",
    "       'Day ahead/Solar in MAW',\n",
    "       'Day ahead/Wind Onshore in MAW', 'Day ahead/Wind Offshore in MAW'], inplace=True)\n",
    "\n",
    "print(df_load.shape)\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Realised/Solar in MAW</th>\n",
       "      <th>Realised/Wind Onshore in MAW</th>\n",
       "      <th>Realised/System total load in MAW</th>\n",
       "      <th>Realised/Wind Offshore in MAW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>203400.000000</td>\n",
       "      <td>203556.000000</td>\n",
       "      <td>203996.000000</td>\n",
       "      <td>203567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4544.078899</td>\n",
       "      <td>9632.608840</td>\n",
       "      <td>55502.542001</td>\n",
       "      <td>1995.614697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6941.546136</td>\n",
       "      <td>7999.657244</td>\n",
       "      <td>10032.550893</td>\n",
       "      <td>1588.686852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>29158.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3556.000000</td>\n",
       "      <td>47109.000000</td>\n",
       "      <td>592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>7189.000000</td>\n",
       "      <td>55121.000000</td>\n",
       "      <td>1662.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7344.000000</td>\n",
       "      <td>13432.000000</td>\n",
       "      <td>64352.250000</td>\n",
       "      <td>3110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33194.000000</td>\n",
       "      <td>40930.000000</td>\n",
       "      <td>77853.000000</td>\n",
       "      <td>6990.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Realised/Solar in MAW  Realised/Wind Onshore in MAW  \\\n",
       "count          203400.000000                 203556.000000   \n",
       "mean             4544.078899                   9632.608840   \n",
       "std              6941.546136                   7999.657244   \n",
       "min                 0.000000                     88.000000   \n",
       "25%                 0.000000                   3556.000000   \n",
       "50%               100.000000                   7189.000000   \n",
       "75%              7344.000000                  13432.000000   \n",
       "max             33194.000000                  40930.000000   \n",
       "\n",
       "       Realised/System total load in MAW  Realised/Wind Offshore in MAW  \n",
       "count                      203996.000000                  203567.000000  \n",
       "mean                        55502.542001                    1995.614697  \n",
       "std                         10032.550893                    1588.686852  \n",
       "min                         29158.000000                       0.000000  \n",
       "25%                         47109.000000                     592.000000  \n",
       "50%                         55121.000000                    1662.000000  \n",
       "75%                         64352.250000                    3110.000000  \n",
       "max                         77853.000000                    6990.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = df_load.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load_norm = min_max_normalize_target_var(df_load.iloc[:,1:]) # avoid Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load = df_load_norm.to_numpy(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204096, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of target variable\n",
    "np_load.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the feature data set is: (204096, 16, 10, 9)\n",
      "The shape of the target data set is: (204096, 4)\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the train set is: (81696, 16, 10, 9)\n",
      "The shape of the target variable is: (81696, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the validation set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the validation set is: (8640, 4)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "The shape of the test set is: (8640, 16, 10, 9)\n",
      "The shape of the target variable for the test set is: (8640, 4)\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(feature_channel, np_load, 90, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train different Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_hyperparameters(X_train, y_train, X_val, y_val, X_test, y_test, window, filter_1, filter_2, optimizer, epochs):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(filter_1, window,\n",
    "              activation='relu',\n",
    "              input_shape=(16, 10, 9))\n",
    "             )\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(filter_2, window,\n",
    "              activation='relu')\n",
    "             )\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_error'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=128,\n",
    "                        epochs = epochs,\n",
    "                        validation_data=(X_val,y_val),\n",
    "                        shuffle=False)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_true = (y_test*100_000).copy()\n",
    "    y_prediction = (y_pred*100_000).copy()\n",
    "    \n",
    "    y_true_with_date = pd.DataFrame({'Date':df_load.iloc[-y_test.shape[0]:,0],\n",
    "                                 'solar':y_true[:,0], \n",
    "                                 'wind_onshore':y_true[:,1], \n",
    "                                 'load':y_true[:,2], \n",
    "                                 'wind_offshore':y_true[:,3]})\n",
    "\n",
    "\n",
    "    list_names = [\"solar\",\"wind_onshore\", \"load\", \"wind_offshore\"]\n",
    "\n",
    "    metrics_dict = dict()\n",
    "    for i in range(len(y_pred[0])):\n",
    "        print(\"\\n=================================\")\n",
    "        print(f\"{list_names[i]}\")\n",
    "        metrics_dict[list_names[i]] = get_model_metrics(y_true_with_date.iloc[:,[0,i+1]],y_prediction[:,i])\n",
    "        print(\"=================================\\n\")\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0542 - mean_absolute_error: 0.1233 - val_loss: 0.0244 - val_mean_absolute_error: 0.1235\n",
      "Epoch 2/50\n",
      "639/639 [==============================] - 11s 16ms/step - loss: 0.0146 - mean_absolute_error: 0.0906 - val_loss: 0.0113 - val_mean_absolute_error: 0.0869\n",
      "Epoch 3/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0124 - mean_absolute_error: 0.0751 - val_loss: 0.0078 - val_mean_absolute_error: 0.0757\n",
      "Epoch 4/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0066 - mean_absolute_error: 0.0581 - val_loss: 0.0042 - val_mean_absolute_error: 0.0517\n",
      "Epoch 5/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0045 - mean_absolute_error: 0.0502 - val_loss: 0.0035 - val_mean_absolute_error: 0.0462\n",
      "Epoch 6/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0040 - mean_absolute_error: 0.0464 - val_loss: 0.0029 - val_mean_absolute_error: 0.0377\n",
      "Epoch 7/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0035 - mean_absolute_error: 0.0428 - val_loss: 0.0033 - val_mean_absolute_error: 0.0396\n",
      "Epoch 8/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0034 - mean_absolute_error: 0.0411 - val_loss: 0.0029 - val_mean_absolute_error: 0.0379\n",
      "Epoch 9/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0030 - mean_absolute_error: 0.0379 - val_loss: 0.0024 - val_mean_absolute_error: 0.0337\n",
      "Epoch 10/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0029 - mean_absolute_error: 0.0370 - val_loss: 0.0029 - val_mean_absolute_error: 0.0372\n",
      "Epoch 11/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0030 - mean_absolute_error: 0.0373 - val_loss: 0.0027 - val_mean_absolute_error: 0.0346\n",
      "Epoch 12/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0029 - mean_absolute_error: 0.0367 - val_loss: 0.0027 - val_mean_absolute_error: 0.0354\n",
      "Epoch 13/50\n",
      "639/639 [==============================] - 11s 17ms/step - loss: 0.0029 - mean_absolute_error: 0.0371 - val_loss: 0.0024 - val_mean_absolute_error: 0.0333\n",
      "Epoch 14/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0028 - mean_absolute_error: 0.0358 - val_loss: 0.0037 - val_mean_absolute_error: 0.0440\n",
      "Epoch 15/50\n",
      "639/639 [==============================] - 10s 15ms/step - loss: 0.0028 - mean_absolute_error: 0.0358 - val_loss: 0.0024 - val_mean_absolute_error: 0.0329\n",
      "Epoch 16/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0027 - mean_absolute_error: 0.0345 - val_loss: 0.0025 - val_mean_absolute_error: 0.0330\n",
      "Epoch 17/50\n",
      "639/639 [==============================] - 11s 17ms/step - loss: 0.0026 - mean_absolute_error: 0.0343 - val_loss: 0.0024 - val_mean_absolute_error: 0.0328\n",
      "Epoch 18/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0026 - mean_absolute_error: 0.0339 - val_loss: 0.0023 - val_mean_absolute_error: 0.0322\n",
      "Epoch 19/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0026 - mean_absolute_error: 0.0338 - val_loss: 0.0028 - val_mean_absolute_error: 0.0352\n",
      "Epoch 20/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0026 - mean_absolute_error: 0.0336 - val_loss: 0.0023 - val_mean_absolute_error: 0.0318\n",
      "Epoch 21/50\n",
      "639/639 [==============================] - 11s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0336 - val_loss: 0.0025 - val_mean_absolute_error: 0.0358\n",
      "Epoch 22/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0025 - mean_absolute_error: 0.0330 - val_loss: 0.0022 - val_mean_absolute_error: 0.0320\n",
      "Epoch 23/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0025 - mean_absolute_error: 0.0332 - val_loss: 0.0022 - val_mean_absolute_error: 0.0319\n",
      "Epoch 24/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0025 - mean_absolute_error: 0.0331 - val_loss: 0.0023 - val_mean_absolute_error: 0.0331\n",
      "Epoch 25/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0326 - val_loss: 0.0022 - val_mean_absolute_error: 0.0315\n",
      "Epoch 26/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0321 - val_loss: 0.0023 - val_mean_absolute_error: 0.0335\n",
      "Epoch 27/50\n",
      "639/639 [==============================] - 11s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0321 - val_loss: 0.0022 - val_mean_absolute_error: 0.0322\n",
      "Epoch 28/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0323 - val_loss: 0.0021 - val_mean_absolute_error: 0.0311\n",
      "Epoch 29/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0317 - val_loss: 0.0021 - val_mean_absolute_error: 0.0320\n",
      "Epoch 30/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0318 - val_loss: 0.0021 - val_mean_absolute_error: 0.0308\n",
      "Epoch 31/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0321 - val_loss: 0.0021 - val_mean_absolute_error: 0.0314\n",
      "Epoch 32/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0318 - val_loss: 0.0023 - val_mean_absolute_error: 0.0331\n",
      "Epoch 33/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0319 - val_loss: 0.0024 - val_mean_absolute_error: 0.0334\n",
      "Epoch 34/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0318 - val_loss: 0.0024 - val_mean_absolute_error: 0.0339\n",
      "Epoch 35/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0325 - val_loss: 0.0023 - val_mean_absolute_error: 0.0337\n",
      "Epoch 36/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0320 - val_loss: 0.0026 - val_mean_absolute_error: 0.0357\n",
      "Epoch 37/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0317 - val_loss: 0.0024 - val_mean_absolute_error: 0.0336\n",
      "Epoch 38/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0317 - val_loss: 0.0022 - val_mean_absolute_error: 0.0335\n",
      "Epoch 39/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0317 - val_loss: 0.0023 - val_mean_absolute_error: 0.0331\n",
      "Epoch 40/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0321 - val_loss: 0.0021 - val_mean_absolute_error: 0.0312\n",
      "Epoch 41/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0318 - val_loss: 0.0024 - val_mean_absolute_error: 0.0338\n",
      "Epoch 42/50\n",
      "639/639 [==============================] - 10s 15ms/step - loss: 0.0024 - mean_absolute_error: 0.0317 - val_loss: 0.0024 - val_mean_absolute_error: 0.0342\n",
      "Epoch 43/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0314 - val_loss: 0.0022 - val_mean_absolute_error: 0.0328\n",
      "Epoch 44/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0317 - val_loss: 0.0023 - val_mean_absolute_error: 0.0332\n",
      "Epoch 45/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0023 - mean_absolute_error: 0.0316 - val_loss: 0.0023 - val_mean_absolute_error: 0.0329\n",
      "Epoch 46/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0024 - mean_absolute_error: 0.0316 - val_loss: 0.0023 - val_mean_absolute_error: 0.0333\n",
      "Epoch 47/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0023 - mean_absolute_error: 0.0314 - val_loss: 0.0021 - val_mean_absolute_error: 0.0317\n",
      "Epoch 48/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0023 - mean_absolute_error: 0.0312 - val_loss: 0.0023 - val_mean_absolute_error: 0.0329\n",
      "Epoch 49/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0023 - mean_absolute_error: 0.0311 - val_loss: 0.0022 - val_mean_absolute_error: 0.0325\n",
      "Epoch 50/50\n",
      "639/639 [==============================] - 10s 16ms/step - loss: 0.0023 - mean_absolute_error: 0.0312 - val_loss: 0.0023 - val_mean_absolute_error: 0.0331\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 24685753.11\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2857.147350515739\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 7.097051635399091\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 17539028.61\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2029.9801635882093\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 10.264399132697307\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 65782648.53\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 7613.732469138503\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 14.572978310293875\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 13558939.18\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 1569.3216649039132\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 18.31796107271557\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history, model = train_model_hyperparameters(X_train, \n",
    "                                             y_train, \n",
    "                                             X_val, \n",
    "                                             y_val, \n",
    "                                             X_test, \n",
    "                                             y_test, \n",
    "                                             (3, 3), \n",
    "                                             128,\n",
    "                                             64,\n",
    "                                             'adam', \n",
    "                                             50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.history\n",
    "plt.plot(history.history[\"loss\"],label = \"loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label = \"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "history.history\n",
    "plt.plot(history.history[\"mean_absolute_error\"],label = \"MAE\")\n",
    "plt.plot(history.history[\"val_mean_absolute_error\"],label = \"val_MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "639/639 [==============================] - 8s 12ms/step - loss: 0.1641 - mean_absolute_error: 0.1661 - val_loss: 0.0037 - val_mean_absolute_error: 0.0425\n",
      "Epoch 2/5\n",
      "639/639 [==============================] - 7s 11ms/step - loss: 0.0039 - mean_absolute_error: 0.0426 - val_loss: 0.0032 - val_mean_absolute_error: 0.0415\n",
      "Epoch 3/5\n",
      "639/639 [==============================] - 7s 11ms/step - loss: 0.0031 - mean_absolute_error: 0.0377 - val_loss: 0.0034 - val_mean_absolute_error: 0.0409\n",
      "Epoch 4/5\n",
      "639/639 [==============================] - 7s 11ms/step - loss: 0.0027 - mean_absolute_error: 0.0351 - val_loss: 0.0031 - val_mean_absolute_error: 0.0381\n",
      "Epoch 5/5\n",
      "639/639 [==============================] - 7s 11ms/step - loss: 0.0026 - mean_absolute_error: 0.0341 - val_loss: 0.0029 - val_mean_absolute_error: 0.0373\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 25525374.82\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2954.3257891441144\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 7.338351651994585\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 21834473.83\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2527.138175226286\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 12.777654400021524\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 55049588.75\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 6371.480179665486\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 12.194209461537557\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 22555358.41\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2610.5738905537114\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 30.47052807237142\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history, model = train_model_hyperparameters(X_train, \n",
    "                                             y_train, \n",
    "                                             X_val, \n",
    "                                             y_val, \n",
    "                                             X_test, \n",
    "                                             y_test, \n",
    "                                             (3, 3), \n",
    "                                             64,\n",
    "                                             128,\n",
    "                                             'rmsprop', \n",
    "                                             5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "639/639 [==============================] - 8s 12ms/step - loss: 0.1929 - mean_absolute_error: 0.1698 - val_loss: 0.0038 - val_mean_absolute_error: 0.0454\n",
      "Epoch 2/5\n",
      "639/639 [==============================] - 8s 12ms/step - loss: 0.0038 - mean_absolute_error: 0.0420 - val_loss: 0.0030 - val_mean_absolute_error: 0.0386\n",
      "Epoch 3/5\n",
      "639/639 [==============================] - 8s 12ms/step - loss: 0.0030 - mean_absolute_error: 0.0370 - val_loss: 0.0026 - val_mean_absolute_error: 0.0344\n",
      "Epoch 4/5\n",
      "639/639 [==============================] - 8s 12ms/step - loss: 0.0028 - mean_absolute_error: 0.0350 - val_loss: 0.0026 - val_mean_absolute_error: 0.0352\n",
      "Epoch 5/5\n",
      "639/639 [==============================] - 8s 12ms/step - loss: 0.0026 - mean_absolute_error: 0.0336 - val_loss: 0.0025 - val_mean_absolute_error: 0.0338\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 24044423.01\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2782.9193295439086\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 6.912861312665248\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 22255819.46\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2575.905030496308\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 13.024260128488834\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 56038243.23\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 6485.907781756256\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 12.413240798284134\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 12689175.06\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 1468.6545205258824\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 17.142156508951757\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history, model = train_model_hyperparameters(X_train, \n",
    "                                             y_train, \n",
    "                                             X_val, \n",
    "                                             y_val, \n",
    "                                             X_test, \n",
    "                                             y_test, \n",
    "                                             (3, 3), \n",
    "                                             64,\n",
    "                                             128,\n",
    "                                             'rmsprop', \n",
    "                                             5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------\n",
      "training model 1...\n",
      "Epoch 1/50\n",
      "639/639 [==============================] - 21s 33ms/step - loss: 0.1837 - mean_absolute_error: 0.1719 - val_loss: 0.0042 - val_mean_absolute_error: 0.0457\n",
      "Epoch 2/50\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.0047 - mean_absolute_error: 0.0469 - val_loss: 0.0040 - val_mean_absolute_error: 0.0458\n",
      "Epoch 3/50\n",
      "639/639 [==============================] - 20s 31ms/step - loss: 0.0038 - mean_absolute_error: 0.0422 - val_loss: 0.0031 - val_mean_absolute_error: 0.0390\n",
      "Epoch 4/50\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.0031 - mean_absolute_error: 0.0377 - val_loss: 0.0030 - val_mean_absolute_error: 0.0384\n",
      "Epoch 5/50\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.0028 - mean_absolute_error: 0.0356 - val_loss: 0.0027 - val_mean_absolute_error: 0.0349\n",
      "Epoch 6/50\n",
      "639/639 [==============================] - 19s 30ms/step - loss: 0.0027 - mean_absolute_error: 0.0347 - val_loss: 0.0036 - val_mean_absolute_error: 0.0467\n",
      "Epoch 7/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0028 - mean_absolute_error: 0.0347 - val_loss: 0.0025 - val_mean_absolute_error: 0.0338\n",
      "Epoch 8/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0025 - mean_absolute_error: 0.0336 - val_loss: 0.0024 - val_mean_absolute_error: 0.0330\n",
      "Epoch 9/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0025 - mean_absolute_error: 0.0334 - val_loss: 0.0024 - val_mean_absolute_error: 0.0327\n",
      "Epoch 10/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0024 - mean_absolute_error: 0.0329 - val_loss: 0.0023 - val_mean_absolute_error: 0.0321\n",
      "Epoch 11/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0024 - mean_absolute_error: 0.0331 - val_loss: 0.0023 - val_mean_absolute_error: 0.0319\n",
      "Epoch 12/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0024 - mean_absolute_error: 0.0325 - val_loss: 0.0022 - val_mean_absolute_error: 0.0312\n",
      "Epoch 13/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0024 - mean_absolute_error: 0.0324 - val_loss: 0.0022 - val_mean_absolute_error: 0.0313\n",
      "Epoch 14/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0024 - mean_absolute_error: 0.0323 - val_loss: 0.0023 - val_mean_absolute_error: 0.0330\n",
      "Epoch 15/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0024 - mean_absolute_error: 0.0321 - val_loss: 0.0024 - val_mean_absolute_error: 0.0338\n",
      "Epoch 16/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0321 - val_loss: 0.0022 - val_mean_absolute_error: 0.0317\n",
      "Epoch 17/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0024 - mean_absolute_error: 0.0318 - val_loss: 0.0023 - val_mean_absolute_error: 0.0327\n",
      "Epoch 18/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0315 - val_loss: 0.0023 - val_mean_absolute_error: 0.0322\n",
      "Epoch 19/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0314 - val_loss: 0.0023 - val_mean_absolute_error: 0.0330\n",
      "Epoch 20/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0312 - val_loss: 0.0023 - val_mean_absolute_error: 0.0328\n",
      "Epoch 21/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0311 - val_loss: 0.0022 - val_mean_absolute_error: 0.0317\n",
      "Epoch 22/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0310 - val_loss: 0.0023 - val_mean_absolute_error: 0.0320\n",
      "Epoch 23/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0310 - val_loss: 0.0023 - val_mean_absolute_error: 0.0319\n",
      "Epoch 24/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0049 - mean_absolute_error: 0.0330 - val_loss: 0.0023 - val_mean_absolute_error: 0.0318\n",
      "Epoch 25/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0310 - val_loss: 0.0022 - val_mean_absolute_error: 0.0316\n",
      "Epoch 26/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0308 - val_loss: 0.0023 - val_mean_absolute_error: 0.0323\n",
      "Epoch 27/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0309 - val_loss: 0.0022 - val_mean_absolute_error: 0.0317\n",
      "Epoch 28/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0308 - val_loss: 0.0023 - val_mean_absolute_error: 0.0321\n",
      "Epoch 29/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0305 - val_loss: 0.0023 - val_mean_absolute_error: 0.0319\n",
      "Epoch 30/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0303 - val_loss: 0.0023 - val_mean_absolute_error: 0.0318\n",
      "Epoch 31/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0305 - val_loss: 0.0023 - val_mean_absolute_error: 0.0324\n",
      "Epoch 32/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0304 - val_loss: 0.0023 - val_mean_absolute_error: 0.0323\n",
      "Epoch 33/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0303 - val_loss: 0.0023 - val_mean_absolute_error: 0.0321\n",
      "Epoch 34/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0028 - mean_absolute_error: 0.0309 - val_loss: 0.0023 - val_mean_absolute_error: 0.0323\n",
      "Epoch 35/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0302 - val_loss: 0.0023 - val_mean_absolute_error: 0.0323\n",
      "Epoch 36/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0027 - mean_absolute_error: 0.0308 - val_loss: 0.0023 - val_mean_absolute_error: 0.0323\n",
      "Epoch 37/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0301 - val_loss: 0.0022 - val_mean_absolute_error: 0.0320\n",
      "Epoch 38/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0302 - val_loss: 0.0023 - val_mean_absolute_error: 0.0325\n",
      "Epoch 39/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0301 - val_loss: 0.0023 - val_mean_absolute_error: 0.0324\n",
      "Epoch 40/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0300 - val_loss: 0.0023 - val_mean_absolute_error: 0.0323\n",
      "Epoch 41/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0300 - val_loss: 0.0023 - val_mean_absolute_error: 0.0322\n",
      "Epoch 42/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0300 - val_loss: 0.0022 - val_mean_absolute_error: 0.0321\n",
      "Epoch 43/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0301 - val_loss: 0.0023 - val_mean_absolute_error: 0.0321\n",
      "Epoch 44/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0300 - val_loss: 0.0022 - val_mean_absolute_error: 0.0316\n",
      "Epoch 45/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0300 - val_loss: 0.0023 - val_mean_absolute_error: 0.0319\n",
      "Epoch 46/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0301 - val_loss: 0.0022 - val_mean_absolute_error: 0.0317\n",
      "Epoch 47/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0302 - val_loss: 0.0022 - val_mean_absolute_error: 0.0318\n",
      "Epoch 48/50\n",
      "639/639 [==============================] - 19s 29ms/step - loss: 0.0021 - mean_absolute_error: 0.0300 - val_loss: 0.0022 - val_mean_absolute_error: 0.0316\n",
      "Epoch 49/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0022 - mean_absolute_error: 0.0300 - val_loss: 0.0022 - val_mean_absolute_error: 0.0316\n",
      "Epoch 50/50\n",
      "639/639 [==============================] - 18s 29ms/step - loss: 0.0027 - mean_absolute_error: 0.0306 - val_loss: 0.0023 - val_mean_absolute_error: 0.0326\n",
      "\n",
      "=================================\n",
      "solar\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 23293996.31\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2696.064387941181\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 6.697143917468189\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_onshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 17599764.06\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 2037.0097286010644\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 10.300318980207255\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "load\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 55423890.02\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 6414.802085114187\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 12.277779472753506\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "wind_offshore\n",
      "\n",
      "----------------------------------------------\n",
      "The absolute error (total actual minus  forecast) in MW is: 10925549.2\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute error of the model in MW is: 1264.531157760829\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "The overall mean absolute scaled error of the model in MW is: 14.760047720193143\n",
      "Please note: to calculate the MASE, the prediction for the first observation was omitted\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "This function also returns a dataframe with the MAE for each day\n",
      "----------------------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "training model 2...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 4 from 3 for '{{node conv2d_9/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](max_pooling2d_8/MaxPool, conv2d_9/Conv2D/ReadVariableOp)' with input shapes: [?,6,3,128], [4,4,128,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1811\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 4 from 3 for '{{node conv2d_9/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](max_pooling2d_8/MaxPool, conv2d_9/Conv2D/ReadVariableOp)' with input shapes: [?,6,3,128], [4,4,128,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-50ae041bc9ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n-----------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'training model {num}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     model_dict[f'model_{num}'] = train_model_hyperparameters(X_train, \n\u001b[0m\u001b[1;32m     12\u001b[0m                                              \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                              \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-4ac33847d490>\u001b[0m in \u001b[0;36mtrain_model_hyperparameters\u001b[0;34m(X_train, y_train, X_val, y_val, X_test, y_test, window, filter_1, filter_2, optimizer, epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m              )\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     model.add(layers.Conv2D(filter_2, window,\n\u001b[0m\u001b[1;32m     10\u001b[0m               activation='relu')\n\u001b[1;32m     11\u001b[0m              )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    926\u001b[0m                                                 input_list)\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m     name=None):\n\u001b[0;32m-> 1010\u001b[0;31m   return convolution_internal(\n\u001b[0m\u001b[1;32m   1011\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m       return op(\n\u001b[0m\u001b[1;32m   1141\u001b[0m           \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2582\u001b[0m     \u001b[0;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m     \u001b[0;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[1;32m   2585\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \"'conv2d' Op, not %r.\" % dilations)\n\u001b[1;32m    974\u001b[0m   \u001b[0mdilations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dilations\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdilations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3475\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3477\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3478\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1974\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   1975\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/residual_load_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 4 from 3 for '{{node conv2d_9/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](max_pooling2d_8/MaxPool, conv2d_9/Conv2D/ReadVariableOp)' with input shapes: [?,6,3,128], [4,4,128,64]."
     ]
    }
   ],
   "source": [
    "first_filters = [256, 128, 64, 64, 128, 256]\n",
    "second_filters = [64, 64, 128, 256, 256, 128]\n",
    "optimizer = ['rmsprop', 'adam', 'rmsprop', 'adam', 'rmsprop', 'adam']\n",
    "sliding_window = [(3,3), (4,4), (3,3), (4,4), (3,3), (4,4)]\n",
    "model_number = range(1,7)\n",
    "\n",
    "model_dict = dict()\n",
    "for num,i,j,k,l in zip(model_number, first_filters, second_filters, optimizer, sliding_window):\n",
    "    print('\\n-----------------------------------------------------------')\n",
    "    print(f'training model {num}...')\n",
    "    model_dict[f'model_{num}'] = train_model_hyperparameters(X_train, \n",
    "                                             y_train, \n",
    "                                             X_val, \n",
    "                                             y_val, \n",
    "                                             X_test, \n",
    "                                             y_test, \n",
    "                                             l, \n",
    "                                             i,\n",
    "                                             j,\n",
    "                                             k, \n",
    "                                             50)\n",
    "    print('-----------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.history\n",
    "plt.plot(history.history[\"loss\"],label = \"loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label = \"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "history.history\n",
    "plt.plot(history.history[\"mean_absolute_error\"],label = \"MAE\")\n",
    "plt.plot(history.history[\"val_mean_absolute_error\"],label = \"val_MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
