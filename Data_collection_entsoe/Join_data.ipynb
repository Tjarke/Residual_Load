{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join the data downloaded from Entso-e to create a unified DataFrame\n",
    "\n",
    "Create one datframe for day-ahead and one for week-ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from Name_convention_dictionaries import PsrTypeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the data type of the dates is datetime:\n",
    "dateparse = lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join all the files for day-ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the day-ahead files\n",
    "folder_name = 'data_day_ahead'\n",
    "files_in_dir = os.listdir(\"./\"+folder_name+\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to create a DataFrame for each document and process type. This means, all the data from regarding e.g. total load is saved in one big DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_if_loaded = []\n",
    "list_of_dfs = []\n",
    "\n",
    "# take the first file in the folder\n",
    "for i in files_in_dir:\n",
    "    group_files = []\n",
    "    \n",
    "    # check if the file has been used before\n",
    "    if i == '.DS_Store':\n",
    "        pass\n",
    "    \n",
    "    elif i[:-38] not in check_if_loaded:\n",
    "        \n",
    "        # you want to group all files in the folder that belong to the same document and process type\n",
    "        # search for all files that have the same characters at the beginning of the file name\n",
    "        for j in files_in_dir:\n",
    "            \n",
    "            # if the selected file has the same characters at the beginning of the file name, save the\n",
    "            # path in the group_files list\n",
    "            if i[:-38] == j[:-38]:\n",
    "                group_files.append(\"./\"+folder_name+\"/\"+j)\n",
    "        \n",
    "        # save the first file in the group_files list as a dataframe in memory\n",
    "        df = pd.read_csv(group_files[0],parse_dates=['Date'], date_parser=dateparse)\n",
    "        \n",
    "        # iterate through all the remaining files in the group_files list and store them as a dataframe\n",
    "        # in memory. Then concatenate all dataframes\n",
    "        for k in group_files[1:]:\n",
    "            df2 = pd.read_csv(k,parse_dates=['Date'], date_parser=dateparse)\n",
    "            df = pd.concat([df,df2])\n",
    "\n",
    "        # Finally, sort the values in the dataframe by datetime and append the dataframe to the\n",
    "        # list_of_dfs. This will be used later to merge all dataframes together\n",
    "        df = df.sort_values(by=[\"Date\"])\n",
    "        list_of_dfs.append(df)\n",
    "        \n",
    "        # Append the first file to the check_if_loaded list to make sure all files with the same document\n",
    "        # and process type are ignored for the next iteration in the loop\n",
    "        check_if_loaded.append(i[:-38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64328\n",
      "0\n",
      "203397\n",
      "0\n",
      "64232\n",
      "0\n",
      "64232\n",
      "0\n",
      "64232\n",
      "0\n",
      "203553\n",
      "0\n",
      "203993\n",
      "0\n",
      "203564\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# search for duplicates and get rid of them\n",
    "for i in list_of_dfs:\n",
    "    print(i.duplicated().sum())\n",
    "    i.drop_duplicates(inplace=True)\n",
    "    print(i.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],\n",
    "                                            how='outer'), list_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.sort_values(by=[\"Date\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new dataframe as a csv file\n",
    "df_merged.to_csv(\"Day_ahead_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Date', 'Day ahead/System total load in MAW',\n",
       "       'Realised/Solar in MAW', 'Day ahead/Solar in MAW',\n",
       "       'Day ahead/Wind Onshore in MAW', 'Day ahead/Wind Offshore in MAW',\n",
       "       'Realised/Wind Onshore in MAW', 'Realised/System total load in MAW',\n",
       "       'Realised/Wind Offshore in MAW'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure all columns have been stored\n",
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                   0\n",
       "Date                                    0\n",
       "Day ahead/System total load in MAW     96\n",
       "Realised/Solar in MAW                 696\n",
       "Day ahead/Solar in MAW                576\n",
       "Day ahead/Wind Onshore in MAW         576\n",
       "Day ahead/Wind Offshore in MAW         96\n",
       "Realised/Wind Onshore in MAW          540\n",
       "Realised/System total load in MAW     100\n",
       "Realised/Wind Offshore in MAW         529\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many nan values are in the DataFrame\n",
    "df_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day ahead/System total load in MAW</th>\n",
       "      <th>Realised/Solar in MAW</th>\n",
       "      <th>Day ahead/Solar in MAW</th>\n",
       "      <th>Day ahead/Wind Onshore in MAW</th>\n",
       "      <th>Day ahead/Wind Offshore in MAW</th>\n",
       "      <th>Realised/Wind Onshore in MAW</th>\n",
       "      <th>Realised/System total load in MAW</th>\n",
       "      <th>Realised/Wind Offshore in MAW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62301</th>\n",
       "      <td>62301</td>\n",
       "      <td>2016-10-10 22:15:00</td>\n",
       "      <td>45588.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2863.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>47864.0</td>\n",
       "      <td>1497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186770</th>\n",
       "      <td>186674</td>\n",
       "      <td>2020-04-29 11:30:00</td>\n",
       "      <td>62651.0</td>\n",
       "      <td>14292.0</td>\n",
       "      <td>15520.0</td>\n",
       "      <td>10895.0</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>8660.0</td>\n",
       "      <td>61022.0</td>\n",
       "      <td>1278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46378</th>\n",
       "      <td>46378</td>\n",
       "      <td>2016-04-28 01:30:00</td>\n",
       "      <td>43617.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9419.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>9426.0</td>\n",
       "      <td>46538.0</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47031</th>\n",
       "      <td>47031</td>\n",
       "      <td>2016-05-04 20:45:00</td>\n",
       "      <td>49049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2974.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>50779.0</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45736</th>\n",
       "      <td>45736</td>\n",
       "      <td>2016-04-21 09:00:00</td>\n",
       "      <td>65438.0</td>\n",
       "      <td>23074.0</td>\n",
       "      <td>22947.0</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>65970.0</td>\n",
       "      <td>534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56033</th>\n",
       "      <td>56033</td>\n",
       "      <td>2016-08-06 15:15:00</td>\n",
       "      <td>48465.0</td>\n",
       "      <td>9341.0</td>\n",
       "      <td>10056.0</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>48809.0</td>\n",
       "      <td>1355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158751</th>\n",
       "      <td>158655</td>\n",
       "      <td>2019-07-12 14:45:00</td>\n",
       "      <td>60914.0</td>\n",
       "      <td>10445.0</td>\n",
       "      <td>11123.0</td>\n",
       "      <td>3631.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>5661.0</td>\n",
       "      <td>61855.0</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180322</th>\n",
       "      <td>180226</td>\n",
       "      <td>2020-02-22 07:30:00</td>\n",
       "      <td>57256.0</td>\n",
       "      <td>5082.0</td>\n",
       "      <td>4268.0</td>\n",
       "      <td>35242.0</td>\n",
       "      <td>5165.0</td>\n",
       "      <td>35985.0</td>\n",
       "      <td>55519.0</td>\n",
       "      <td>3233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33182</th>\n",
       "      <td>33182</td>\n",
       "      <td>2015-12-12 14:30:00</td>\n",
       "      <td>56959.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>11043.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>8413.0</td>\n",
       "      <td>55516.0</td>\n",
       "      <td>1422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180163</th>\n",
       "      <td>180067</td>\n",
       "      <td>2020-02-20 15:45:00</td>\n",
       "      <td>68169.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>25817.0</td>\n",
       "      <td>5897.0</td>\n",
       "      <td>28153.0</td>\n",
       "      <td>67182.0</td>\n",
       "      <td>5696.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                Date  Day ahead/System total load in MAW  \\\n",
       "62301    62301 2016-10-10 22:15:00                             45588.0   \n",
       "186770  186674 2020-04-29 11:30:00                             62651.0   \n",
       "46378    46378 2016-04-28 01:30:00                             43617.0   \n",
       "47031    47031 2016-05-04 20:45:00                             49049.0   \n",
       "45736    45736 2016-04-21 09:00:00                             65438.0   \n",
       "56033    56033 2016-08-06 15:15:00                             48465.0   \n",
       "158751  158655 2019-07-12 14:45:00                             60914.0   \n",
       "180322  180226 2020-02-22 07:30:00                             57256.0   \n",
       "33182    33182 2015-12-12 14:30:00                             56959.0   \n",
       "180163  180067 2020-02-20 15:45:00                             68169.0   \n",
       "\n",
       "        Realised/Solar in MAW  Day ahead/Solar in MAW  \\\n",
       "62301                     0.0                     0.0   \n",
       "186770                14292.0                 15520.0   \n",
       "46378                     0.0                     0.0   \n",
       "47031                     0.0                     0.0   \n",
       "45736                 23074.0                 22947.0   \n",
       "56033                  9341.0                 10056.0   \n",
       "158751                10445.0                 11123.0   \n",
       "180322                 5082.0                  4268.0   \n",
       "33182                   509.0                   599.0   \n",
       "180163                 1429.0                  1096.0   \n",
       "\n",
       "        Day ahead/Wind Onshore in MAW  Day ahead/Wind Offshore in MAW  \\\n",
       "62301                          2863.0                          1853.0   \n",
       "186770                        10895.0                          1377.0   \n",
       "46378                          9419.0                          1118.0   \n",
       "47031                          2974.0                           444.0   \n",
       "45736                          2795.0                           551.0   \n",
       "56033                          9748.0                          2014.0   \n",
       "158751                         3631.0                           326.0   \n",
       "180322                        35242.0                          5165.0   \n",
       "33182                         11043.0                          1625.0   \n",
       "180163                        25817.0                          5897.0   \n",
       "\n",
       "        Realised/Wind Onshore in MAW  Realised/System total load in MAW  \\\n",
       "62301                         1979.0                            47864.0   \n",
       "186770                        8660.0                            61022.0   \n",
       "46378                         9426.0                            46538.0   \n",
       "47031                         3909.0                            50779.0   \n",
       "45736                         1785.0                            65970.0   \n",
       "56033                         8939.0                            48809.0   \n",
       "158751                        5661.0                            61855.0   \n",
       "180322                       35985.0                            55519.0   \n",
       "33182                         8413.0                            55516.0   \n",
       "180163                       28153.0                            67182.0   \n",
       "\n",
       "        Realised/Wind Offshore in MAW  \n",
       "62301                          1497.0  \n",
       "186770                         1278.0  \n",
       "46378                          1365.0  \n",
       "47031                           295.0  \n",
       "45736                           534.0  \n",
       "56033                          1355.0  \n",
       "158751                          640.0  \n",
       "180322                         3233.0  \n",
       "33182                          1422.0  \n",
       "180163                         5696.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join all the files for week-ahead predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the day-ahead files\n",
    "folder_name = 'data_week_ahead'\n",
    "files_in_dir = os.listdir(\"./\"+folder_name+\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task for the week-ahead prediction is much simpler than day-ahead (as there are no actuals or generation values). use a simpler implementation to save some memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the paths to the files. So they can be saved as DataFrames\n",
    "list_of_paths = []\n",
    "for name in files_in_dir:\n",
    "    list_of_paths.append(\"./\"+folder_name+\"/\"+name)\n",
    "\n",
    "# store the DataFrames in memory and concatenate them\n",
    "df_week = pd.read_csv(list_of_paths[0], parse_dates=['min_date', 'max_date'], date_parser=dateparse)\n",
    "for file in list_of_paths[1:]:\n",
    "    df2 = pd.read_csv(file, parse_dates=['min_date', 'max_date'], date_parser=dateparse)\n",
    "    df_week = pd.concat([df_week, df2])\n",
    "    \n",
    "df_week.sort_values(by=['min_date', 'max_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of all duplicates before saving the data as a csv\n",
    "df_week.drop_duplicates(inplace=True)\n",
    "\n",
    "df_week.to_csv('Week_ahead_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>min_forecast_in_MAW</th>\n",
       "      <th>max_forecast_in_MAW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2016-09-12 22:00:00</td>\n",
       "      <td>2016-09-12 22:00:00</td>\n",
       "      <td>37577</td>\n",
       "      <td>64954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2020-01-17 23:00:00</td>\n",
       "      <td>2020-01-17 23:00:00</td>\n",
       "      <td>48367</td>\n",
       "      <td>67684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2019-01-24 23:00:00</td>\n",
       "      <td>2019-01-24 23:00:00</td>\n",
       "      <td>52284</td>\n",
       "      <td>72776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2015-10-24 22:00:00</td>\n",
       "      <td>2015-10-24 22:00:00</td>\n",
       "      <td>40549</td>\n",
       "      <td>57156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2018-03-12 23:00:00</td>\n",
       "      <td>2018-03-12 23:00:00</td>\n",
       "      <td>45686</td>\n",
       "      <td>70838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2019-02-09 23:00:00</td>\n",
       "      <td>2019-02-09 23:00:00</td>\n",
       "      <td>48509</td>\n",
       "      <td>62658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-11-11 23:00:00</td>\n",
       "      <td>2018-11-11 23:00:00</td>\n",
       "      <td>40863</td>\n",
       "      <td>56475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-11-19 23:00:00</td>\n",
       "      <td>2019-11-19 23:00:00</td>\n",
       "      <td>48264</td>\n",
       "      <td>70047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2019-08-08 22:00:00</td>\n",
       "      <td>2019-08-08 22:00:00</td>\n",
       "      <td>40759</td>\n",
       "      <td>63715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2018-03-09 23:00:00</td>\n",
       "      <td>2018-03-09 23:00:00</td>\n",
       "      <td>50584</td>\n",
       "      <td>71165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               min_date            max_date  min_forecast_in_MAW  \\\n",
       "301 2016-09-12 22:00:00 2016-09-12 22:00:00                37577   \n",
       "81  2020-01-17 23:00:00 2020-01-17 23:00:00                48367   \n",
       "94  2019-01-24 23:00:00 2019-01-24 23:00:00                52284   \n",
       "257 2015-10-24 22:00:00 2015-10-24 22:00:00                40549   \n",
       "140 2018-03-12 23:00:00 2018-03-12 23:00:00                45686   \n",
       "110 2019-02-09 23:00:00 2019-02-09 23:00:00                48509   \n",
       "20  2018-11-11 23:00:00 2018-11-11 23:00:00                40863   \n",
       "29  2019-11-19 23:00:00 2019-11-19 23:00:00                48264   \n",
       "283 2019-08-08 22:00:00 2019-08-08 22:00:00                40759   \n",
       "137 2018-03-09 23:00:00 2018-03-09 23:00:00                50584   \n",
       "\n",
       "     max_forecast_in_MAW  \n",
       "301                64954  \n",
       "81                 67684  \n",
       "94                 72776  \n",
       "257                57156  \n",
       "140                70838  \n",
       "110                62658  \n",
       "20                 56475  \n",
       "29                 70047  \n",
       "283                63715  \n",
       "137                71165  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_week.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
