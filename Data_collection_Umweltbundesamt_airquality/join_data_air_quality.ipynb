{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data_air_quality_thursday/\"\n",
    "files_in_dir = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"&station=1025date_from=2016-01-01&time_from=1&date_to=2016-10-25&time_from=23.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_file_string(name):\n",
    "    if name[-67] == \"d\":\n",
    "        return name[:-67]\n",
    "    elif name[-68] == \"d\":\n",
    "        return name[:-68]\n",
    "    else:\n",
    "        raise Exception(f\"Input not in desired format. It was {name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_dir = os.listdir(path)\n",
    "check_if_loaded = []\n",
    "list_of_dfs = []\n",
    "\n",
    "for i in files_in_dir:\n",
    "    group_files = []\n",
    "    if format_file_string(i) not in check_if_loaded:\n",
    "        for j in files_in_dir:\n",
    "            if format_file_string(i) == format_file_string(j):\n",
    "                group_files.append(path+j)\n",
    "        df = pd.read_csv(group_files[0],parse_dates=[0])\n",
    "        \n",
    "        for k in group_files[1:]:\n",
    "            df2 = pd.read_csv(k,parse_dates=[0])\n",
    "            df = pd.concat([df,df2])\n",
    "        df = df.sort_values(by=[\"Date\"])\n",
    "        list_of_dfs.append(df)\n",
    "        check_if_loaded.append(format_file_string(i))\n",
    "     #   print(f\"loaded {format_file_string(i)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We get duplicates because of the summer/ wintertime ... also we have to transform to utc for entso-e \n",
    "# Daylight saving time 2016 in Germany began at 02:00 on Sunday, 27 March and ended at 03:00 on Sunday, 30 October\n",
    "# Daylight saving time 2017 in Germany began at 02:00 on Sunday, 26 March and ended at 03:00 on Sunday, 29 October\n",
    "# Daylight saving time 2018 in Germany began at 02:00 on Sunday, 25 March and ended at 03:00 on Sunday , 28 October\n",
    "# Daylight saving time 2019 in Germany began at 02:00 on Sunday, 31 March and ended at 03:00 on Sunday, 27 October\n",
    "# Daylight saving time 2020 in Germany began at 02:00 on Sunday, 29 March and ended at 03:00 on Sunday, 25 October\n",
    "# Summer utc = berlin - 2, Winter utc = Berlin - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_switches = [\n",
    "    \"2011-01-01 00:00:00\",\n",
    "    \"2016-03-27 02:00:01\",\n",
    "    \"2016-10-30 03:00:00\",\n",
    "    \"2017-03-26 02:00:01\",\n",
    "    \"2017-10-29 03:00:00\",\n",
    "    \"2018-03-25 02:00:01\",\n",
    "    \"2018-10-28 03:00:00\",\n",
    "    \"2019-03-31 02:00:01\",\n",
    "    \"2019-10-27 03:00:00\",\n",
    "    \"2020-03-29 02:00:01\",\n",
    "    \"2020-10-25 03:00:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we transform our data to utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt,i in enumerate(list_of_dfs):\n",
    "    df = list_of_dfs[cnt]\n",
    "    df = df.reset_index()\n",
    "    for j in range(len(time_switches)-1):\n",
    "        mask = ((df.loc[:,'Date'] > time_switches[j]) & (df.loc[:,'Date'] < time_switches[j+1]))\n",
    "        if j%2 == 0:\n",
    "            df.loc[mask,\"Date\"] -= datetime.timedelta(hours=1)\n",
    "        else:\n",
    "            df.loc[mask,\"Date\"] -= datetime.timedelta(hours=2)\n",
    "            mask2 = df.loc[:,'Date']  == time_switches[j+1]\n",
    "            df.loc[mask2.idxmax(),\"Date\"] -= datetime.timedelta(hours=2)\n",
    "            mask2 = df.loc[:,'Date']  == time_switches[j+1]\n",
    "            df.loc[mask2.idxmax(),\"Date\"] -= datetime.timedelta(hours=1)\n",
    "    df = df .sort_values(by=[\"Date\"])\n",
    "    df = df.drop(columns=\"index\")\n",
    "    list_of_dfs[cnt] = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_of_dfs:\n",
    "    if i.loc[:,\"Date\"].duplicated().any():\n",
    "        print(\"not succesfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_merged = []\n",
    "for i in range(0,len(list_of_dfs)-10,10):\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],\n",
    "                                            how='outer'), list_of_dfs[i:i+10])\n",
    "    list_merged.append(df_merged.copy())\n",
    "\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],\n",
    "                                            how='outer'), list_of_dfs[len(list_merged)*10:])\n",
    "list_merged.append(df_merged.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],\n",
    "                                            how='outer'), list_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.sort_values(by=[\"Date\"])\n",
    "df_merged = df_merged.replace([\"-\"],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dropped = []\n",
    "\n",
    "for i in df_merged:\n",
    "    number_nan_rows = df_merged.loc[df_merged.loc[:,i].isnull(),i].shape[0]\n",
    "    percentage_nan_rows = number_nan_rows/df_merged.shape[0]*100\n",
    "    if (percentage_nan_rows > 25):\n",
    "        columns_dropped.append([i,percentage_nan_rows])\n",
    "        df_merged = df_merged.drop(columns=[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.loc[:, df_merged.columns != \"Date\"] = df_merged.loc[:, df_merged.columns != \"Date\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.sort_values(by=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "notebook stop cell below for saving",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d7d3644b72ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"notebook stop cell below for saving\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: notebook stop cell below for saving"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"notebook stop cell below for saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"air_quality.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
